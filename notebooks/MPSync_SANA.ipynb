{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from diffusers import SanaPipeline, SanaPAGPipeline\n",
    "from models.multiplane_sync.processors_sana import (\n",
    "    apply_custom_processors_for_vae,\n",
    "    apply_custom_processors_for_transformer,\n",
    "    get_patch_embed_forward,\n",
    ")\n",
    "\n",
    "def build_pipeline(model_name: str):\n",
    "    if model_name == 'sana':\n",
    "        pipe = SanaPipeline.from_pretrained(\n",
    "            \"Efficient-Large-Model/Sana_1600M_1024px_BF16_diffusers\",\n",
    "            variant=\"bf16\",\n",
    "            torch_dtype=torch.bfloat16,\n",
    "            local_files_only=True,\n",
    "        )\n",
    "    elif model_name == 'sana-pag':\n",
    "        pipe = SanaPAGPipeline.from_pretrained(\n",
    "            \"Efficient-Large-Model/Sana_1600M_1024px_BF16_diffusers\",\n",
    "            variant=\"bf16\",\n",
    "            torch_dtype=torch.bfloat16,\n",
    "            pag_applied_layers=\"transformer_blocks.8\",\n",
    "            local_files_only=True,\n",
    "        )\n",
    "    pipe.text_encoder.to(torch.bfloat16)\n",
    "    pipe.vae.to(torch.bfloat16)\n",
    "    return pipe.to(\"cuda\")\n",
    "\n",
    "model_name = 'sana-pag'\n",
    "\n",
    "pipe = build_pipeline(model_name)\n",
    "\n",
    "apply_custom_processors_for_vae(pipe.vae, enable_sync_attn=True, enable_sync_conv2d=True, enable_sync_gn=True)\n",
    "apply_custom_processors_for_transformer(pipe.transformer, enable_sync_self_attn=True, enable_sync_conv2d=True, enable_sync_gn=True)\n",
    "pipe.transformer.patch_embed.forward = get_patch_embed_forward(pipe.transformer.patch_embed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from einops import rearrange\n",
    "import numpy as np\n",
    "from utils.cube import images_to_equi_and_dice, concat_dice_mask\n",
    "\n",
    "\n",
    "prompt = 'Floating in the sky, pixel style, white clouds, hot air balloons, and a blue sky'\n",
    "height, width = 1024, 1024\n",
    "\n",
    "# Inference\n",
    "outputs = pipe(\n",
    "    prompt=[prompt] * 6,\n",
    "    height=height,\n",
    "    width=width,\n",
    "    output_type='np',\n",
    ").images\n",
    "\n",
    "# To PIL\n",
    "images = rearrange(outputs, '(b m) ... -> b m ...', m=6)\n",
    "equis, dices = images_to_equi_and_dice(images)\n",
    "equi_rgb_pil = Image.fromarray((equis[0] * 255).astype(np.uint8))\n",
    "dice_rgb_pil = Image.fromarray((dices[0] * 255).astype(np.uint8))\n",
    "dice_rgb_pil = concat_dice_mask(dice_rgb_pil)\n",
    "\n",
    "# Show\n",
    "equi_rgb_pil.resize((1024, 512)).show()\n",
    "dice_rgb_pil.resize((1024, 768)).show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
